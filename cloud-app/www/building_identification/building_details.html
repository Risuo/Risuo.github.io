<!doctype html>
<html lang="en" xml:lang="en" xmlns="http://www.w3.org/1999/xhtml">

<head>
    <!-- Required meta tags -->
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta charset="utf-8">
    <title>Building Identification Details</title>
    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet"
          integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">

    <!-- Option 1: Bootstrap Bundle with Popper -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"
            integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p"
            crossorigin="anonymous"></script>

</head>
<body>
<nav class="navbar navbar-expand-lg navbar-light bg-light">
    <div class="container-xl my-md-4">
        <a class="navbar-brand" href="../index.html"><h1>Peter Scott Miller</h1></a>
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent"
                aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarSupportedContent">
            <ul class="navbar-nav me-auto mb-2 mb-lg-0">
                <li class="nav-item">
                    <a class="nav-link active" aria-current="page" href="../about.html">About Me!</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link active" aria-current="page" href="../index.html">Home</a>
                </li>
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button"
                       data-bs-toggle="dropdown" aria-expanded="false">
                        Navigate
                    </a>
                    <ul class="dropdown-menu" aria-labelledby="navbarDropdown">
                        <li><a class="dropdown-item" href="../index.html">Home</a></li>
                        <li><a class="dropdown-item" href="./index.html">Building
                            Identification</a></li>
                        <li><a class="dropdown-item" href="../sketcher/index.html">Quick-Sketch</a></li>
                        <li>
                            <hr class="dropdown-divider">
                        </li>
                        <li><a class="dropdown-item" href="./building_details.html">Building
                            Identification - Details</a></li>
                        <li><a class="dropdown-item" href="../sketcher/sketcher_details.html">Quick-Sketch - Details</a>
                        </li>
                    </ul>
                </li>
            </ul>
        </div>
    </div>
</nav>
<!-- bs4 css-->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.1.0/css/bootstrap.min.css"/>

<!-- main css-->
<link rel="stylesheet" href="css/building_identification.css">

<div class="container-xl my-md-4">
    <div class="portfolio">

        <div class="accordion-item">

            <h2 class="accordion-header" id="headingOne">
                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse"
                        data-bs-target="#collapseOne" aria-expanded="false" aria-controls="collapseOne">
                    Data wrangling, conversion, processing, augmentation, and formatting
                </button>
            </h2>
            <div id="collapseOne" class="accordion-collapse collapse" aria-labelledby="headingOne"
                 data-bs-parent="#accordionExample">

                <div class="accordion-body">
                    <am class="row">
                        <li> This page will be updated with data and steps that depend on the Python Notebook (.ipynb)
                            files located in my github
                            here: <a
                                    href="https://github.com/Risuo/Risuo.github.io.old/tree/master/Building%20Identification/Python%20Notebooks"
                                    target="_blank"
                                    title="Python Notebooks - Building Identification">Python Notebooks - Building
                                Identification</a> and
                            <a href="https://github.com/Risuo/Risuo.github.io.old/tree/master/Building%20Identification/Paperspace%20Converted%20Code"
                               target="_blank"
                               title="Python - Paperspace Converted Code">Python - Paperspace Converted Code </a>
                            as well as many other sources.
                        </li>
                        <li>The basic project line was as follows: Decide it would be cool to have a website that would
                            let you scroll around a Google Maps satellite image to wherever you wanted, click a button,
                            and have a trained ML algorithm perform semantic segmentation on all the buildings.
                        </li>
                        <li>Leaving the data wrangling, conversion, processing, augmentation, and formatting to another
                            section, the website pipeline is as follows:
                        </li>
                        <p></p>
                    </am>
                </div>
            </div>
        </div>
        <div class="accordion-item">
            <h2 class="accordion-header" id="headingTwo">
                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse"
                        data-bs-target="#collapseTwo" aria-expanded="false" aria-controls="collapseTwo">
                    Website Pipeline Breakdown
                </button>
            </h2>
            <div id="collapseTwo" class="accordion-collapse collapse" aria-labelledby="headingTwo"
                 data-bs-parent="#accordionExample">
                <div class="accordion-body">
                    <am class="row">
                        <atl class="col-sm-2">
                            <strong>
                                <li>This section pertains to the Cloud App portion of the website.</li>
                            </strong>
                            <li>First Stage: Create the static satellite image & send to the storage bucket:</li>
                        </atl>
                        <at class="col-sm-10">
                            <p>&nbsp</p>
                            <p>&nbsp</p>
                            <li>User is presented with a static pre-API-call Google Maps JavaScript window.</li>
                            <li>User activates the Google Maps JavaScript window, and is
                                assigned a unique (based on browser identity), impermanent Firebase userID.
                                <p></p>
                                <img src="images/details/function appendMap().PNG" alt="appendMap()">
                                <p></p>
                            </li>
                            <li>Firebase authenticates Google API key, activates window, initializes a count variable to
                                zero.
                                <p></p>
                                <img src="images/details/initialize()%20firebase%20reset,%20signin,%20count.PNG"
                                     alt="initialize()">
                                <p></p>
                            </li>
                            <li>User scrolls around, zooms in, out, decides they've found a spot.</li>
                            <li>During the above step, the map object is constantly listening and resstablishing
                                the center, zoom, and bounds of the JavaScript map object.
                                <p></p>
                                <img src="images/details/getMapBoundsEtc.PNG" alt="getBounds">
                                <p></p>
                            </li>
                            <li>User presses on the "Run Building Identification on current Map View!" button.</li>
                            <li>The counter is incremented, bounds are split into north, south, east, and west corners,
                                ML serving button is hidden.
                                <p></p>
                                <img src="images/details/convert%20bounds,%20increment,%20show%20feedback.PNG"
                                     alt="cardinals & feedback">
                                <p></p>
                            </li>
                            <li>Using the earlier established center and zoom values, create a string to be used in the
                                next asynchronous function.
                                <p></p>
                                <img src="images/details/staticImageAddress.PNG"
                                     alt="pull static image">
                                <p></p>
                            </li>
                            <li>Using the impermanent userID from firebase, establish the firebase.storage() location
                                that the static image is going to be sent to.
                                <p></p>
                                <img src="images/details/async-1.PNG"
                                     alt="async step 1">
                                <p></p>
                            </li>
                            <li>Fetch the Static Map image from Google Static Maps API, once received, send to the
                                'satellite_screenshots' folder within the Google Cloud Storage bucket,
                                appending the userID & count variables (as described in the preceeding step).
                                <p></p>
                                <img src="images/details/async-2.PNG"
                                     alt="async step 2">
                                <p></p>
                            </li>
                            <li>Meanwhile, the above steps are wrapped in an asynchronous function, which performs the
                                following process:
                                <ul>Begin an asynchronous function to fetch and store the static image.</ul>
                                <ul>Simultaneously, begin the first asyncCharacterPrint function, which provides
                                    user-feedback data to let them know that the static image has been
                                    retrieved, and sent to the ML processing container.
                                </ul>
                                <ul>Wait for receipt of two promises, one for the completion of the static image pull,
                                    and the second for the completion of the asyncCharacterPrint.
                                </ul>
                                <ul>Once both promises are received, begin the second asyncCharacterPrint call,
                                    indicating that the image has been received and MP processing has begun.
                                </ul>
                                <p></p>
                                <img src="images/details/fullAsyncCall.PNG"
                                     alt="full asyncCall">
                                <p></p>
                            </li>
                        </at>
                        <atl class="col-sm-3">
                            <strong>
                                <li>This section pertains to the Cloud Run portion of the website.</li>
                            </strong>
                            <li>Second Stage: Run the ML on the image:</li>
                        </atl>
                        <at class="col-sm-8">
                            <p>&nbsp</p>
                            <p>&nbsp</p>
                            <li>First we have to let the Cloud Run instance know that there's a reason for it to spin
                                up, specifically, that a file has been selected by the User, and that it should pull
                                that image and identify as many buildings as it can on it.
                            </li>
                            <li>This is achieved by having setup a pubsub topic subscrition to monitor the
                                satellite_screenshots folder for either of two status updates:
                                OBJECT_FINALIZE or OBJECT_METADATA_UPDATE.
                            </li>
                            <li>When either of those status updates occur, a Push notification is sent to
                                the subscriber, which in this case is the service account associated with the cloud-run
                                instance containing the Dockerized Detectron2 model, with post-transfer learning weights
                                for building identification.
                            </li>
                            <li>The cloud-run instance has an API setup to listen for a POST request, which is expecting
                                a formatted JSON file which includes data relating to the satellite image.
                            </li>
                            <li>
                                Using Flask, we start off by creating an envelope object formatting the data contained
                                in the POST call and verify the contents of the envelope.
                                <p></p>
                                <img src="images/details/cloudRun-1.PNG"
                                     alt="create envelope & verify contents">
                                <p></p>
                            </li>
                            <li>
                                Next the container extracts the bucket_path and file_path locations from the envelope,
                                establishes the storage.Client() object, the bucket object, and the blob object.
                                <p></p>
                                <img src="images/details/cloudRun-2.PNG"
                                     alt="establish necessary objects">
                                <p></p>
                            </li>
                            <li>
                                Next we link the file_name to the blob.name, and format it to allow for successfully
                                using it again later. We then create two temporary files using mkstemp(), which
                                creates a tuple in the form (int, path). We ignore the int portion.
                                <p></p>
                                <img src="images/details/cloudRun-3.PNG"
                                     alt="create two temporary files">
                                <p></p>
                            </li>
                            <li>
                                Now we download the image into the first temporary file, open it, and convert it into a
                                NumPy formatted array.
                                <p></p>
                                <img src="images/details/cloudRun-4.PNG"
                                     alt="download the image & convert to NumPy array">
                                <p></p>
                            </li>
                            <li>
                                <ul>
                                    Now we finally run the image through the pre-trained, specialized Detectron2
                                    algorithm to get a collection of predictions (in the form of another NumPy array).
                                </ul>
                                <ul>
                                    Next we use Detectron2 functions to create a Visualizer object, and scale the image
                                    down to save on the user-download needs (improves interaction speed).
                                </ul>
                                <ul>
                                    Then we draw the actual predictions (which are an array of instances, since this is
                                    semantic segmentation) and crucially, do so via a CPU (but we could use a GPU
                                    instead by redeploying this image on a Google Cloud Google Kubernetes Engine
                                    Enterprise Anthos Cloud Run. This would increase costs by a factor of over 10).
                                </ul>
                                <p></p>
                                <img src="images/details/cloudRun-5.PNG"
                                     alt="run prediction on the image!">
                                <p></p>
                            </li>
                            <li>
                                <ul>
                                    Now we grab the formatted image from that the cpu-drawn output.
                                </ul>
                                <ul>
                                    Having created our prediction file name, we append .png to the second temporary file
                                    from earlier. We take out predicted_img object, and convert it into an Image (since
                                    right now it's still an array). We then save the Image into our second tempoary
                                    file, and
                                    identify it as png format.
                                </ul>
                                <ul>
                                    Finally, we create a pointer to a location in our bucket expecting a new blob
                                    object,
                                    formatted using the prediction_name established earlier. Then we just upload our
                                    second
                                    temporary file (now an image file) into that identified location.
                                </ul>
                                <p></p>
                                <img src="images/details/cloudRun-6.PNG"
                                     alt="save the predicted image into the cloud">
                                <p></p>
                            </li>
                        </at>
                        <atl class="col-sm-3">
                            <strong>
                                <li>This section pertains to the Cloud App portion of the website again.</li>
                            </strong>
                            <li>Third Stage: Display the processed image on the dynamic Google Maps window:</li>
                        </atl>
                        <at class="col-sm-8">
                            <p>&nbsp</p>
                            <p>&nbsp</p>
                            <li>Immediately after the ML processing button as been pressed, the website begins
                                attempting to load the processed image. It does this every .5 seconds It performs
                                repeated getDownloadURL() requests, using the predetermined naming convention.
                                <p></p>
                                <img src="images/details/cloudAppEnd-4.PNG"
                                     alt="actual loop that pulls processed image">
                                <p></p>
                                <ul>
                                    This get request uses the format we've just established in the Cloud Run file, but
                                    at the start of the calls, this file doesn't exist yet. These have to be equal:
                                    <p></p>
                                    <img src="images/details/cloudAppEnd-1.PNG"
                                         alt="this has to equal">
                                    <p></p>
                                    <p></p>
                                    <img src="images/details/cloudAppEnd-2.PNG"
                                         alt="this">
                                    <p></p>
                                    <p></p>
                                    <img src="images/details/cloudAppEnd-3.PNG"
                                         alt="AND this">
                                    <p></p>
                                </ul>
                            </li>
                            <li>Once there is an affirmative response of this URL existing where we're looking (which
                                means the image processing is completed and the processed image has been uploaded
                                successfully into the Google Cloud Bucket) we:
                                <ul>
                                    Create a Ground Overlay object out of the predicted image, and place it on the
                                    dynamic JavaScript Maps image, using the earlier defined bounds information saved
                                    when pressing the Run Building Identification on Current Map View button.
                                    <p></p>
                                    <img src="images/details/cloudAppEnd-5.PNG"
                                         alt="AND this">
                                    <p></p>
                                </ul>
                                <ul>
                                    Present some user-facing data, and re-enable the button.
                                    <p></p>
                                    <img src="images/details/cloudAppEnd-8.PNG"
                                         alt="AND this">
                                    <p></p>
                                </ul>


                        </at>
                    </am>
                </div>
            </div>
        </div>

    </div>
</div>